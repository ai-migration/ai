import os
from typing import List, Dict
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
load_dotenv()  # âœ… .env í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

#ë²„ì „ ë³€í™˜ ê¸°ëŠ¥ ì½”ë“œ

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë”© í•¨ìˆ˜
def load_prompt_template(version: str) -> str:
    import os
    prompt_path = os.path.join("docs", "prompt_version_downgrade.txt")
    with open(prompt_path, "r", encoding="utf-8") as f:
        template = f.read()
    return template.replace("{{target_version}}", version)


# ë³€í™˜ ì‹¤í–‰ í•¨ìˆ˜
def transform_code_to_versions(input_code: str, versions: List[str], model_name: str = "gpt-4") -> dict:
    llm = ChatOpenAI(
        model=model_name,
        openai_api_key=os.getenv("OPENAI_API_KEY")  # âœ… ì—¬ê¸°ë¥¼ ë°˜ë“œì‹œ í™•ì¸
    )
    results = {}
    for version in versions:
        prompt = load_prompt_template(version).replace("{{input_code}}", input_code)
        output = llm.predict(prompt)
        results[version] = output
    return results

# ì‹¤ì œ ì‹¤í–‰ ë¡œì§
if __name__ == "__main__":
    file_path = "examples/TestController.java"

    # íŒŒì¼ ë‚´ìš© ì½ê¸°
    with open(file_path, "r", encoding="utf-8") as f:
        input_code = f.read()

    # ë³€í™˜ ëŒ€ìƒ ë²„ì „ ë¦¬ìŠ¤íŠ¸ ì§€ì •
    target_versions = ["2.7.1", "3.2.0", "3.5.1", "3.6.0", "3.7.0", "3.9.0"]

    # ë³€í™˜ ì‹¤í–‰
    transformed = transform_code_to_versions(input_code, target_versions)

    # ê²°ê³¼ ì¶œë ¥ ë° íŒŒì¼ ì €ì¥
    for version, code in transformed.items():
        print(f"\nğŸ“¦ [eGovFrame {version}] ë³€í™˜ ê²°ê³¼:")
        print("=" * 60)
        print(code)

        output_path = f"converted/converted_{version}.java"
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(code)







